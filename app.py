import streamlit as st
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os

# ======================
# 1. .envï¼ˆAPIã‚­ãƒ¼ï¼‰ã®èª­ã¿è¾¼ã¿
# ======================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ======================
# 2. LLMé–¢æ•°ã®å®šç¾©
# ======================
def get_llm_answer(user_text: str, expert_type: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’å—ã‘å–ã‚Šã€
    LLMã®å›ç­”ã‚’æ–‡å­—åˆ—ã§è¿”ã™
    """

    # å°‚é–€å®¶ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    system_prompt = {
        "AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢": "ã‚ãªãŸã¯å„ªç§€ãªAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚ç›¸æ‰‹ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "Webãƒãƒ¼ã‚±ã‚¿ãƒ¼": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®Webãƒãƒ¼ã‚±ã‚¿ãƒ¼ã§ã™ã€‚å£²ã‚Œã‚‹æ–‡ç« ã§ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¦ãã ã•ã„ã€‚"
    }[expert_type]

    model = ChatOpenAI(
        model="gpt-4.1-mini",
        temperature=0.7,
        api_key=OPENAI_API_KEY
    )

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_text)
    ]

    result = model.invoke(messages)
    return result.content


# ======================
# 3. Streamlit UI
# ======================
st.set_page_config(page_title="LangChain LLM App", layout="wide")

st.title("ğŸš€ LangChain Ã— OpenAI LLMã‚¢ãƒ—ãƒª")

st.write("""
ã“ã®Webã‚¢ãƒ—ãƒªã§ã¯ä»¥ä¸‹ã®ã“ã¨ãŒã§ãã¾ã™ï¼š

- ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã¨AIãŒå›ç­”ã—ã¦ãã‚Œã¾ã™  
- **å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ï¼ˆAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ or Webãƒãƒ¼ã‚±ã‚¿ãƒ¼ï¼‰**ã‚’é¸ã¹ã¾ã™  
- é¸æŠã—ãŸå°‚é–€å®¶è¦–ç‚¹ã§å›ç­”ãŒå¤‰ã‚ã‚Šã¾ã™  
""")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼ˆå°‚é–€å®¶é¸æŠï¼‰
expert = st.radio(
    "ã©ã®ã‚¿ã‚¤ãƒ—ã®å°‚é–€å®¶ã«ç›¸è«‡ã—ã¾ã™ã‹ï¼Ÿ",
    ["AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "Webãƒãƒ¼ã‚±ã‚¿ãƒ¼"]
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_area("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", height=120)

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("AIã«èã"):
    if not user_input.strip():
        st.warning("âš  å…¥åŠ›ãŒå¿…è¦ã§ã™")
    else:
        with st.spinner("AIãŒå›ç­”ä¸­..."):
            answer = get_llm_answer(user_input, expert)
            st.success("å›ç­”ã¯ã“ã¡ã‚‰ğŸ‘‡")
            st.write(answer)


st.write("---")
st.caption("Powered by LangChain & Streamlit / Python 3.11 ã§ãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½")
